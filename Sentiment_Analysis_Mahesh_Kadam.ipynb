{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68e301fa",
   "metadata": {},
   "source": [
    "### Mahesh Kadam Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f812d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "%matplotlib inline\n",
    "import string\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.svm import SVC\n",
    "#from nltk.stem.porter import PorterStemmer\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53f6045f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_location</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>polarity</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>8/19/2021 23:59</td>\n",
       "      <td>cant recall told troops afghanistan falsely ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>-0.300</td>\n",
       "      <td>['afghanistan']</td>\n",
       "      <td>twitter for iphone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>washington, dc</td>\n",
       "      <td>8/19/2021 23:59</td>\n",
       "      <td>shocker afghanistan taliban carrying doorto do...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.000</td>\n",
       "      <td>['afghanistan']</td>\n",
       "      <td>twitter for ipad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>8/19/2021 23:59</td>\n",
       "      <td>drop bass bombs big homie afghanistan talibans</td>\n",
       "      <td>negative</td>\n",
       "      <td>-0.075</td>\n",
       "      <td>['afghanistan', 'talibans']</td>\n",
       "      <td>twitter for iphone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>midnapore, west bengal, uk outreach</td>\n",
       "      <td>8/19/2021 23:59</td>\n",
       "      <td>burqa prices risen markets afghanistans provin...</td>\n",
       "      <td>negative</td>\n",
       "      <td>-0.250</td>\n",
       "      <td>['afghanistan']</td>\n",
       "      <td>twitter web app</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>york, england</td>\n",
       "      <td>8/19/2021 23:59</td>\n",
       "      <td>uk carved afghanistan s heroin minorities mili...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.000</td>\n",
       "      <td>['afghanistan']</td>\n",
       "      <td>twitter for ipad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          user_location             date  \\\n",
       "0                                   NaN  8/19/2021 23:59   \n",
       "1                        washington, dc  8/19/2021 23:59   \n",
       "2                                   NaN  8/19/2021 23:59   \n",
       "3  midnapore, west bengal, uk outreach   8/19/2021 23:59   \n",
       "4                         york, england  8/19/2021 23:59   \n",
       "\n",
       "                                                text sentiment  polarity  \\\n",
       "0    cant recall told troops afghanistan falsely ...  negative    -0.300   \n",
       "1  shocker afghanistan taliban carrying doorto do...   neutral     0.000   \n",
       "2     drop bass bombs big homie afghanistan talibans  negative    -0.075   \n",
       "3  burqa prices risen markets afghanistans provin...  negative    -0.250   \n",
       "4  uk carved afghanistan s heroin minorities mili...   neutral     0.000   \n",
       "\n",
       "                      hashtags              source  \n",
       "0              ['afghanistan']  twitter for iphone  \n",
       "1              ['afghanistan']    twitter for ipad  \n",
       "2  ['afghanistan', 'talibans']  twitter for iphone  \n",
       "3              ['afghanistan']     twitter web app  \n",
       "4              ['afghanistan']    twitter for ipad  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= pd.read_csv('US-Afghan_war_tweets.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40792c33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\mahesh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a519934",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(362566, 6)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dffin = df.drop('polarity',axis=1)\n",
    "dffin.head()\n",
    "dffin.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47f36cea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_location</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>261572</td>\n",
       "      <td>362565</td>\n",
       "      <td>362565</td>\n",
       "      <td>362566</td>\n",
       "      <td>276205</td>\n",
       "      <td>362562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>35072</td>\n",
       "      <td>12354</td>\n",
       "      <td>359903</td>\n",
       "      <td>3</td>\n",
       "      <td>74712</td>\n",
       "      <td>415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>india</td>\n",
       "      <td>8/16/2021 20:22</td>\n",
       "      <td>monday morning total chaos kabul airport gun...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>['afghanistan']</td>\n",
       "      <td>twitter for android</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>11355</td>\n",
       "      <td>288</td>\n",
       "      <td>468</td>\n",
       "      <td>168244</td>\n",
       "      <td>56964</td>\n",
       "      <td>143342</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_location             date  \\\n",
       "count         261572           362565   \n",
       "unique         35072            12354   \n",
       "top            india  8/16/2021 20:22   \n",
       "freq           11355              288   \n",
       "\n",
       "                                                     text sentiment  \\\n",
       "count                                              362565    362566   \n",
       "unique                                             359903         3   \n",
       "top       monday morning total chaos kabul airport gun...   neutral   \n",
       "freq                                                  468    168244   \n",
       "\n",
       "               hashtags               source  \n",
       "count            276205               362562  \n",
       "unique            74712                  415  \n",
       "top     ['afghanistan']  twitter for android  \n",
       "freq              56964               143342  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dffin.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c00997",
   "metadata": {},
   "source": [
    "### 3 unique values for target variable shown count for the same below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35e899ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral     168244\n",
       "negative    117863\n",
       "positive     76459\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dffin['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f303d699",
   "metadata": {},
   "source": [
    "### only 1 observation contains missing value for text data on which we are predicting our target "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d2e2176",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dffin['text'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "06160355",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(362565, 6)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dffin = dffin.dropna(subset=['text'])\n",
    "dffin.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7b5c704c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_location    0.278551\n",
       "date             0.000000\n",
       "text             0.000000\n",
       "sentiment        0.000000\n",
       "hashtags         0.238192\n",
       "source           0.000008\n",
       "dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dffin.isnull().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af85dffd",
   "metadata": {},
   "source": [
    "### we want to preprocess and predict sentiment based on text variable so will preprocess and use for model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8d2bc0d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mahesh\\AppData\\Local\\Temp/ipykernel_13704/4034992228.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dffin['text'] = dffin['text'].astype(str)\n"
     ]
    }
   ],
   "source": [
    "dffin['text'] = dffin['text'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e21d80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "901b767c",
   "metadata": {},
   "source": [
    "### consider sample data for traning due to machine computational capacity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3168dd60",
   "metadata": {},
   "outputs": [],
   "source": [
    "dffortrain = dffin[0:50000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813435cb",
   "metadata": {},
   "source": [
    "### Preprocessing text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5038a447",
   "metadata": {},
   "source": [
    "### Takes in a string of text, then performs the following:\n",
    "#### 1. Remove all punctuation\n",
    "#### 2. Remove all stopwords\n",
    "#### 3. Return the cleaned text as a list of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d142a139",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_process(text):\n",
    "    nopunc = [char for char in text if char not in string.punctuation]\n",
    "    nopunc = ''.join(nopunc)\n",
    "    words = [word for word in nopunc.split() if word.lower() not in stopwords.words('english')]\n",
    "    #words = [PorterStemmer().stem(w) for w in words]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c5ed162c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mahesh\\AppData\\Local\\Temp/ipykernel_13704/3329978925.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dffortrain['processed_text'] = new_processed_text\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "new_processed_text =[]\n",
    "tweets = list(dffortrain['text'])     \n",
    "for k in tweets:\n",
    "    count = count +1\n",
    "    new_processed_text.append(text_process(k))\n",
    "\n",
    "dffortrain['processed_text'] = new_processed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "24f390f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_location</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>source</th>\n",
       "      <th>processed_text</th>\n",
       "      <th>processed_text_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>8/19/2021 23:59</td>\n",
       "      <td>cant recall told troops afghanistan falsely ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>['afghanistan']</td>\n",
       "      <td>twitter for iphone</td>\n",
       "      <td>[cant, recall, told, troops, afghanistan, fals...</td>\n",
       "      <td>cant recal told troop afghanistan fals claim o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>washington, dc</td>\n",
       "      <td>8/19/2021 23:59</td>\n",
       "      <td>shocker afghanistan taliban carrying doorto do...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>['afghanistan']</td>\n",
       "      <td>twitter for ipad</td>\n",
       "      <td>[shocker, afghanistan, taliban, carrying, door...</td>\n",
       "      <td>shocker afghanistan taliban carri doorto door ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>8/19/2021 23:59</td>\n",
       "      <td>drop bass bombs big homie afghanistan talibans</td>\n",
       "      <td>negative</td>\n",
       "      <td>['afghanistan', 'talibans']</td>\n",
       "      <td>twitter for iphone</td>\n",
       "      <td>[drop, bass, bombs, big, homie, afghanistan, t...</td>\n",
       "      <td>drop bass bomb big homi afghanistan taliban</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>midnapore, west bengal, uk outreach</td>\n",
       "      <td>8/19/2021 23:59</td>\n",
       "      <td>burqa prices risen markets afghanistans provin...</td>\n",
       "      <td>negative</td>\n",
       "      <td>['afghanistan']</td>\n",
       "      <td>twitter web app</td>\n",
       "      <td>[burqa, prices, risen, markets, afghanistans, ...</td>\n",
       "      <td>burqa price risen market afghanistan provinc a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>york, england</td>\n",
       "      <td>8/19/2021 23:59</td>\n",
       "      <td>uk carved afghanistan s heroin minorities mili...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>['afghanistan']</td>\n",
       "      <td>twitter for ipad</td>\n",
       "      <td>[uk, carved, afghanistan, heroin, minorities, ...</td>\n",
       "      <td>uk carv afghanistan heroin minor milit guess c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>everywhere</td>\n",
       "      <td>8/17/2021 19:19</td>\n",
       "      <td>biden administration worst us history</td>\n",
       "      <td>negative</td>\n",
       "      <td>['biden', 'us']</td>\n",
       "      <td>twitter for iphone</td>\n",
       "      <td>[biden, administration, worst, us, history]</td>\n",
       "      <td>biden administr worst us histori</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>NaN</td>\n",
       "      <td>8/17/2021 19:19</td>\n",
       "      <td>lives civilians protected us eu started shed c...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>['us', 'eu', 'ethiopia']</td>\n",
       "      <td>twitter for android</td>\n",
       "      <td>[lives, civilians, protected, us, eu, started,...</td>\n",
       "      <td>live civilian protect us eu start shed crocodi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>NaN</td>\n",
       "      <td>8/17/2021 19:18</td>\n",
       "      <td>us messed afghanistan want mess beautiful amp ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>['us', 'afghanistan', 'ethiopia']</td>\n",
       "      <td>twitter for android</td>\n",
       "      <td>[us, messed, afghanistan, want, mess, beautifu...</td>\n",
       "      <td>us mess afghanistan want mess beauti amp ancie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>ã â¤â¦ã â¤â¿ã â¤â²ã â¥âã â¤â²ã â¥â ã â¤âµã â...</td>\n",
       "      <td>8/17/2021 19:18</td>\n",
       "      <td>us military bosses better job keeping morale h...</td>\n",
       "      <td>positive</td>\n",
       "      <td>['us', 'military']</td>\n",
       "      <td>twitter for android</td>\n",
       "      <td>[us, military, bosses, better, job, keeping, m...</td>\n",
       "      <td>us militari boss better job keep moral high am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50000</th>\n",
       "      <td>ethiopia</td>\n",
       "      <td>8/17/2021 19:18</td>\n",
       "      <td>plummet afghanistans government retaliation ta...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>NaN</td>\n",
       "      <td>twitter web app</td>\n",
       "      <td>[plummet, afghanistans, government, retaliatio...</td>\n",
       "      <td>plummet afghanistan govern retali taliban indi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           user_location             date  \\\n",
       "0                                                    NaN  8/19/2021 23:59   \n",
       "1                                         washington, dc  8/19/2021 23:59   \n",
       "2                                                    NaN  8/19/2021 23:59   \n",
       "3                   midnapore, west bengal, uk outreach   8/19/2021 23:59   \n",
       "4                                          york, england  8/19/2021 23:59   \n",
       "...                                                  ...              ...   \n",
       "49996                                         everywhere  8/17/2021 19:19   \n",
       "49997                                                NaN  8/17/2021 19:19   \n",
       "49998                                                NaN  8/17/2021 19:18   \n",
       "49999  ã â¤â¦ã â¤â¿ã â¤â²ã â¥âã â¤â²ã â¥â ã â¤âµã â...  8/17/2021 19:18   \n",
       "50000                                           ethiopia  8/17/2021 19:18   \n",
       "\n",
       "                                                    text sentiment  \\\n",
       "0        cant recall told troops afghanistan falsely ...  negative   \n",
       "1      shocker afghanistan taliban carrying doorto do...   neutral   \n",
       "2         drop bass bombs big homie afghanistan talibans  negative   \n",
       "3      burqa prices risen markets afghanistans provin...  negative   \n",
       "4      uk carved afghanistan s heroin minorities mili...   neutral   \n",
       "...                                                  ...       ...   \n",
       "49996              biden administration worst us history  negative   \n",
       "49997  lives civilians protected us eu started shed c...   neutral   \n",
       "49998  us messed afghanistan want mess beautiful amp ...  positive   \n",
       "49999  us military bosses better job keeping morale h...  positive   \n",
       "50000  plummet afghanistans government retaliation ta...   neutral   \n",
       "\n",
       "                                hashtags               source  \\\n",
       "0                        ['afghanistan']   twitter for iphone   \n",
       "1                        ['afghanistan']     twitter for ipad   \n",
       "2            ['afghanistan', 'talibans']   twitter for iphone   \n",
       "3                        ['afghanistan']      twitter web app   \n",
       "4                        ['afghanistan']     twitter for ipad   \n",
       "...                                  ...                  ...   \n",
       "49996                    ['biden', 'us']   twitter for iphone   \n",
       "49997           ['us', 'eu', 'ethiopia']  twitter for android   \n",
       "49998  ['us', 'afghanistan', 'ethiopia']  twitter for android   \n",
       "49999                 ['us', 'military']  twitter for android   \n",
       "50000                                NaN      twitter web app   \n",
       "\n",
       "                                          processed_text  \\\n",
       "0      [cant, recall, told, troops, afghanistan, fals...   \n",
       "1      [shocker, afghanistan, taliban, carrying, door...   \n",
       "2      [drop, bass, bombs, big, homie, afghanistan, t...   \n",
       "3      [burqa, prices, risen, markets, afghanistans, ...   \n",
       "4      [uk, carved, afghanistan, heroin, minorities, ...   \n",
       "...                                                  ...   \n",
       "49996        [biden, administration, worst, us, history]   \n",
       "49997  [lives, civilians, protected, us, eu, started,...   \n",
       "49998  [us, messed, afghanistan, want, mess, beautifu...   \n",
       "49999  [us, military, bosses, better, job, keeping, m...   \n",
       "50000  [plummet, afghanistans, government, retaliatio...   \n",
       "\n",
       "                                        processed_text_2  \n",
       "0      cant recal told troop afghanistan fals claim o...  \n",
       "1      shocker afghanistan taliban carri doorto door ...  \n",
       "2           drop bass bomb big homi afghanistan taliban   \n",
       "3      burqa price risen market afghanistan provinc a...  \n",
       "4      uk carv afghanistan heroin minor milit guess c...  \n",
       "...                                                  ...  \n",
       "49996                  biden administr worst us histori   \n",
       "49997  live civilian protect us eu start shed crocodi...  \n",
       "49998  us mess afghanistan want mess beauti amp ancie...  \n",
       "49999  us militari boss better job keep moral high am...  \n",
       "50000  plummet afghanistan govern retali taliban indi...  \n",
       "\n",
       "[50000 rows x 8 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dffortrain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c2b102",
   "metadata": {},
   "source": [
    "### unlist the processed text for spliting in train test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a68a7ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unlist(list):\n",
    "    words=''\n",
    "    for item in list:\n",
    "        words+=item+' '\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "56b4b3c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mahesh\\AppData\\Local\\Temp/ipykernel_13704/745024313.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dffortrain['processed_text_2'] = dffortrain['processed_text'].apply(lambda x: unlist(x))\n"
     ]
    }
   ],
   "source": [
    "dffortrain['processed_text_2'] = dffortrain['processed_text'].apply(lambda x: unlist(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "aa46f4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dffortrain.to_csv(\"clntext.csv\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4e26ca7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test,y_train,y_test = train_test_split(dffortrain['processed_text_2'],dffortrain['sentiment'],test_size=0.2,random_state=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e932446a",
   "metadata": {},
   "source": [
    "### Term Frequency Inverse Document Frequency importance weightage to words reprensenting in vector form for maodel building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f043c8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfid = TfidfVectorizer(max_features=5000)\n",
    "features= tfid.fit_transform(X_train)\n",
    "features_test = tfid.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8010cde5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 5000)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2847ad",
   "metadata": {},
   "source": [
    "### implemented 3 different models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29fbd92c",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "640ea3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "model = MultinomialNB()\n",
    "model.fit(features,y_train)\n",
    "label_pred= model.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c2366aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics as m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e999fad4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8279"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.accuracy_score(y_test,label_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f6397c",
   "metadata": {},
   "source": [
    "## SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0c80bf5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8906"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1 =SVC(kernel='sigmoid', gamma=1,C=1)\n",
    "model1.fit(features,y_train)\n",
    "label_pred1= model1.predict(features_test)\n",
    "m.accuracy_score(y_test,label_pred1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f4fad0",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "30f4d8a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mahesh\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8805"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model2 =LogisticRegression()\n",
    "model2.fit(features,y_train)\n",
    "label_pred2= model2.predict(features_test)\n",
    "m.accuracy_score(y_test,label_pred2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679e3b0d",
   "metadata": {},
   "source": [
    "### from above 3 models SVC gives better Score 89.06%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b44b0d",
   "metadata": {},
   "source": [
    "### using RandomizedSearchCV for tuning hyperparameter(C, gamma, kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cc7d9828",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cs = [0.001, 0.01, 0.1, 1, 10]\n",
    "#gammas = [0.001, 0.01, 0.1, 1, 10]\n",
    "param_grid = {\"gamma\": [0.001, 0.01, 0.1, 1, 10], \"C\": [0.001, 0.01, 0.1, 1, 10],\"kernel\": ['rbf', 'poly', 'sigmoid']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a4cf49be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "cv = StratifiedShuffleSplit(n_splits=3, test_size=0.2, random_state=10)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ef86211e",
   "metadata": {},
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "grid_cv = GridSearchCV(model1, param_grid=param_grid, cv=cv)\n",
    "grid_cv.fit(features, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "040cbcca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=StratifiedShuffleSplit(n_splits=3, random_state=10, test_size=0.2,\n",
       "            train_size=None),\n",
       "                   estimator=SVC(C=1, gamma=1), n_jobs=-1,\n",
       "                   param_distributions={'C': [0.001, 0.01, 0.1, 1, 10],\n",
       "                                        'gamma': [0.001, 0.01, 0.1, 1, 10],\n",
       "                                        'kernel': ['rbf', 'poly', 'sigmoid']})"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "rand_grid = RandomizedSearchCV(model11, param_distributions=param_grid,cv=cv,n_jobs=-1)\n",
    "rand_grid.fit(features,y_train_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7f1dc349",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'kernel': 'rbf', 'gamma': 0.1, 'C': 10}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc334d7",
   "metadata": {},
   "source": [
    "### this step taking too much time for my machine so didt tried different iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37db1674",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8153afbf",
   "metadata": {},
   "source": [
    "### To handel Imbalanced data used SMOTE from oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8251ed09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'neutral': 20722, 'positive': 10354, 'negative': 8924})\n"
     ]
    }
   ],
   "source": [
    "from collections impo\n",
    "rt Counter\n",
    "print(Counter(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2886ee29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mahesh\\anaconda3\\lib\\site-packages\\imblearn\\utils\\_validation.py:587: FutureWarning: Pass sampling_strategy=auto as keyword args. From version 0.9 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "osamp = SMOTE('auto',n_jobs=-1)\n",
    "features,y_train_smote = osamp.fit_resample(features,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6b015336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'neutral': 20722, 'negative': 20722, 'positive': 20722})\n"
     ]
    }
   ],
   "source": [
    "print(Counter(y_train_smote))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c947847",
   "metadata": {},
   "source": [
    "## Model after treating with imbalance data and hypertunning parameters\n",
    "## 'kernel': 'rbf', 'gamma': 0.1, 'C': 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "383efc28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9031"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model11 =SVC(kernel='rbf', gamma=0.1,C=10)\n",
    "model11.fit(features,y_train_smote)\n",
    "label_pred11= model11.predict(features_test)\n",
    "m.accuracy_score(y_test,label_pred11)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64955537",
   "metadata": {},
   "source": [
    "### final tunned SVC model11 for prediction on test dataset 90.31%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a3a47dac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['neutral' 'neutral' 'neutral' ... 'positive' 'positive' 'neutral']\n"
     ]
    }
   ],
   "source": [
    "print(label_pred11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b437070a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.72      0.80      2219\n",
      "     neutral       0.90      0.98      0.94      5200\n",
      "    positive       0.92      0.90      0.91      2581\n",
      "\n",
      "    accuracy                           0.90     10000\n",
      "   macro avg       0.91      0.87      0.88     10000\n",
      "weighted avg       0.90      0.90      0.90     10000\n",
      "\n",
      "[[1599  428  192]\n",
      " [  69 5108   23]\n",
      " [  97  160 2324]]\n"
     ]
    }
   ],
   "source": [
    "print(m.classification_report(y_test,label_pred11))\n",
    "print(m.confusion_matrix(y_test,label_pred11))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c5d425",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323169db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
